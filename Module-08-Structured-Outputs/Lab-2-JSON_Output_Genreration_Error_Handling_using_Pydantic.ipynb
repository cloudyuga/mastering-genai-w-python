{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUid2-yaD8Sp"
      },
      "source": [
        "#**Calculate Employee's Term Life Insurance as per the Payscale**\n",
        "\n",
        "###**Reliable JSON Output Generation with LLM, Parsing the JSON output for error handling & Pydantic (for JSON Schema Validation)**\n",
        "\n",
        "#####**✅ Problem:**\n",
        "\n",
        "When interacting with LLMs, we often want structured output (like JSON) rather than freeform text. However, models may produce output that:\n",
        "\n",
        "- Is not valid JSON.\n",
        "\n",
        "- Does not follow a pre-defined schema.\n",
        "\n",
        "- Fails integration with downstream systems expecting structured data.\n",
        "\n",
        "#####**🛠️ Solution:**\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "\n",
        "- Prompt the LLM to return JSON output explicitly.\n",
        "\n",
        "- Use JSON Schema to validate the structure of the output.\n",
        "\n",
        "- Handle model responses gracefully when schema validation fails.\n",
        "\n",
        "#####**Example Techniques Used:**\n",
        "\n",
        "- Prompt engineering for instructing the LLM to produce JSON.\n",
        "\n",
        "- Validation via jsonschema module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dWIMoBlGnd4"
      },
      "source": [
        "###**Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qbw79rSNGuAt",
        "outputId": "778b5e22-f181-421f-dd82-46fd88fa0d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B40xz4ELGfEI"
      },
      "source": [
        "###**Import Required Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m5czD9KVD7Eo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Dict\n",
        "from pydantic import BaseModel, ValidationError, RootModel\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwcm5J8i7b66"
      },
      "source": [
        "###**Get API key from Secret and Set as ENV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vi_SQXuI-ElE"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "# Retrieve the API key from Colab's secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A3tabeSF5sBx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Set the API key (recommended: store securely, not hardcoded)\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJBIAfZfGxhZ"
      },
      "source": [
        "###**Set Up OpenAI Client**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sRXBBbr6HDnr"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTbgJqRdb8F1"
      },
      "source": [
        "###**Generate Response Using Prompt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eY7DLUKr3Kb",
        "outputId": "511679ee-7609-44d6-a6a3-3b159c0e1b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw output:\n",
            " {\n",
            "  \"employee1\": {\n",
            "    \"name\": \"Alice\",\n",
            "    \"age\": 30,\n",
            "    \"payscale\": \"$60,000\",\n",
            "    \"city\": \"New York\"\n",
            "  },\n",
            "  \"employee2\": {\n",
            "    \"name\": \"Bob\",\n",
            "    \"age\": 35,\n",
            "    \"payscale\": \"$55,000\",\n",
            "    \"city\": \"Los Angeles\"\n",
            "  },\n",
            "  \"employee3\": {\n",
            "    \"name\": \"Charlie\",\n",
            "    \"age\": 28,\n",
            "    \"payscale\": \"$50,000\",\n",
            "    \"city\": \"Chicago\"\n",
            "  },\n",
            "  \"employee4\": {\n",
            "    \"name\": \"David\",\n",
            "    \"age\": 40,\n",
            "    \"payscale\": \"$70,000\",\n",
            "    \"city\": \"Houston\"\n",
            "  },\n",
            "  \"employee5\": {\n",
            "    \"name\": \"Emily\",\n",
            "    \"age\": 25,\n",
            "    \"payscale\": \"$45,000\",\n",
            "    \"city\": \"Miami\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#JSON Output Generation\n",
        "prompt = \"\"\"\n",
        "Generate name, age, payscale and city of 5 employees like employee1, employee2 etc.\n",
        "Respond ONLY with a JSON object.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "output = response.choices[0].message.content.strip()\n",
        "print(\"Raw output:\\n\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YaEh0SIot0a4"
      },
      "outputs": [],
      "source": [
        "# Convert string to dictionary\n",
        "data = json.loads(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceJabY1muUbR",
        "outputId": "71d773fc-a9ef-44f0-e45b-f9f3606ad5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'employee1': {'name': 'Alice', 'age': 30, 'payscale': '$60,000', 'city': 'New York'}, 'employee2': {'name': 'Bob', 'age': 35, 'payscale': '$55,000', 'city': 'Los Angeles'}, 'employee3': {'name': 'Charlie', 'age': 28, 'payscale': '$50,000', 'city': 'Chicago'}, 'employee4': {'name': 'David', 'age': 40, 'payscale': '$70,000', 'city': 'Houston'}, 'employee5': {'name': 'Emily', 'age': 25, 'payscale': '$45,000', 'city': 'Miami'}}\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhP2qhC1sNfM",
        "outputId": "640c0aab-e1be-451b-83dd-3d3325bf949d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Employee1 Term life insurance: $60,000$60,000$60,000$60,000\n"
          ]
        }
      ],
      "source": [
        "# Access employee1's salary to calculate term life insurance provided ny company\n",
        "print(\"Employee1 Term life insurance:\", data[\"employee1\"][\"payscale\"]*4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdGDTAxmHuro"
      },
      "source": [
        "###**Define Pydantic Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Aj8kZVqBxeDD"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, field_validator\n",
        "from typing import List, Optional\n",
        "\n",
        "import re\n",
        "\n",
        "class PersonInfo(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    payscale: int\n",
        "    city: str\n",
        "\n",
        "    @field_validator('payscale', mode='before')\n",
        "    @classmethod\n",
        "    def parse_payscale(cls, v):\n",
        "        if isinstance(v, int):\n",
        "            return v\n",
        "        if isinstance(v, str):\n",
        "            # Remove $ and commas\n",
        "            cleaned = re.sub(r'[^\\d]', '', v)\n",
        "            return int(cleaned)\n",
        "        raise ValueError(\"Invalid payscale format\")\n",
        "\n",
        "class EmployeeDict(BaseModel):\n",
        "    employees: List[PersonInfo]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB4Mgek4H-WW"
      },
      "source": [
        "###**Compose Prompt and Call GPT**\n",
        "- JSON Output Generation\n",
        "- Parsing the JSON output for error handling\n",
        "- Schema validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdXFtSlqIJxV",
        "outputId": "e1c934d5-e400-43e3-ce52-bd029dafd617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw output:\n",
            " {\n",
            "  \"employees\": [\n",
            "    {\n",
            "      \"name\": \"employee1\",\n",
            "      \"age\": 30,\n",
            "      \"payscale\": \"$50,000\",\n",
            "      \"city\": \"New York\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"employee2\",\n",
            "      \"age\": 35,\n",
            "      \"payscale\": \"$60,000\",\n",
            "      \"city\": \"Los Angeles\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"employee3\",\n",
            "      \"age\": 28,\n",
            "      \"payscale\": \"$45,000\",\n",
            "      \"city\": \"Chicago\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"employee4\",\n",
            "      \"age\": 32,\n",
            "      \"payscale\": \"$55,000\",\n",
            "      \"city\": \"Houston\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"employee5\",\n",
            "      \"age\": 40,\n",
            "      \"payscale\": \"$70,000\",\n",
            "      \"city\": \"Miami\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "✅ Validated Data:\n",
            " {'employees': [{'name': 'employee1', 'age': 30, 'payscale': 50000, 'city': 'New York'}, {'name': 'employee2', 'age': 35, 'payscale': 60000, 'city': 'Los Angeles'}, {'name': 'employee3', 'age': 28, 'payscale': 45000, 'city': 'Chicago'}, {'name': 'employee4', 'age': 32, 'payscale': 55000, 'city': 'Houston'}, {'name': 'employee5', 'age': 40, 'payscale': 70000, 'city': 'Miami'}]}\n"
          ]
        }
      ],
      "source": [
        "#JSON Output Generation\n",
        "prompt = \"\"\"\n",
        "Generate a JSON object containing a list of 5 employees.\n",
        "Each employee object in the list should have the following keys: \"name\", \"age\", \"payscale\", and \"city\".\n",
        "The top-level key of the JSON object should be \"employees\".\n",
        "Respond ONLY with a JSON object.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    output = response.choices[0].message.content.strip()\n",
        "    print(\"Raw output:\\n\", output)\n",
        "\n",
        "    try:\n",
        "        #Parsing the JSON output for error handling\n",
        "        data = json.loads(output)\n",
        "        # Schema validation\n",
        "        validated_data = EmployeeDict.model_validate(data)\n",
        "        print(\"\\n✅ Validated Data:\\n\", validated_data.model_dump())\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"❌ JSON parsing failed:\", e)\n",
        "    except ValidationError as ve:\n",
        "        print(\"❌ Validation failed:\", ve)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"OpenAI API error:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yfxyo-igwNzz"
      },
      "outputs": [],
      "source": [
        "data_dict = validated_data.model_dump()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr0EERBUzDu-",
        "outputId": "b4a40978-4a9a-4167-bbac-e009bdb928dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250000\n"
          ]
        }
      ],
      "source": [
        "print(data_dict['employees'][0]['payscale'] * 5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
